{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Punvireakroth/animal-detection/blob/main/Animal_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBPxr8gK8_V5"
      },
      "source": [
        "\n",
        "# Environment Setup & Dataset Preparation\n",
        "\n",
        "This phase covers:\n",
        "1. Installing required packages\n",
        "2. Downloading and exploring the dataset\n",
        "3. Implementing 80/10/10 data split\n",
        "4. Creating YOLO directory structure\n",
        "5. Converting annotations to YOLO format\n",
        "6. Generating data.yaml configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RLbXdd-l8_V6",
        "outputId": "3529318a-0cb3-4f33-c6c7-8dc7bf422abb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Installing required packages...\n",
            "============================================================\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ All packages installed successfully!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Install Required Packages\n",
        "print(\"📦 Installing required packages...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "%pip install -q ultralytics opencv-python matplotlib pandas kagglehub scikit-learn pyyaml\n",
        "%pip install -q seaborn pillow tqdm\n",
        "\n",
        "print(\"✅ All packages installed successfully!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6VHUGArZ8_V7",
        "outputId": "ecd7cb47-0f34-4556-c2e4-db02a59a6ba8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All libraries imported successfully!\n",
            "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Current working directory: /content\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import Libraries and Setup Environment\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import yaml\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter, defaultdict\n",
        "import kagglehub\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure matplotlib\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(\"✅ All libraries imported successfully!\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wGuaDsG08_V8",
        "outputId": "36168a58-24c8-4bd9-c8e0-ca31938287bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔽 Downloading animal detection dataset from Kaggle...\n",
            "============================================================\n",
            "Using Colab cache for faster access to the 'animals10' dataset.\n",
            "✅ Dataset downloaded successfully!\n",
            "📁 Dataset location: /kaggle/input/animals10\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Download Dataset from Kaggle\n",
        "print(\"🔽 Downloading animal detection dataset from Kaggle...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    # Download the dataset using kagglehub\n",
        "    # Using \"animals-10\" dataset which has multiple animal classes\n",
        "    dataset_path = kagglehub.dataset_download(\"alessiocorrado99/animals10\")\n",
        "\n",
        "    print(f\"✅ Dataset downloaded successfully!\")\n",
        "    print(f\"📁 Dataset location: {dataset_path}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error downloading dataset: {e}\")\n",
        "    print(\"Please ensure you have Kaggle API configured.\")\n",
        "    print(\"Follow these steps:\")\n",
        "    print(\"1. Go to https://www.kaggle.com/settings\")\n",
        "    print(\"2. Create a new API token\")\n",
        "    print(\"3. Place kaggle.json in ~/.kaggle/\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOUFRpgB8_V9",
        "outputId": "da31b0c0-3d90-4237-c5fd-4cd45f4d0257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Exploring dataset structure...\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Explore Dataset Structure\n",
        "print(\"🔍 Exploring dataset structure...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Find all images in dataset\n",
        "image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
        "all_images = []\n",
        "class_names = set()\n",
        "\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if Path(file).suffix.lower() in image_extensions:\n",
        "            full_path = os.path.join(root, file)\n",
        "            # Extract class name from directory structure\n",
        "            class_name = Path(root).name\n",
        "            if class_name and class_name != os.path.basename(dataset_path):\n",
        "                all_images.append({\n",
        "                    'path': full_path,\n",
        "                    'class': class_name,\n",
        "                    'filename': file\n",
        "                })\n",
        "                class_names.add(class_name)\n",
        "\n",
        "# Create DataFrame\n",
        "df_images = pd.DataFrame(all_images)\n",
        "\n",
        "print(f\"📊 Dataset Statistics:\")\n",
        "print(f\"   Total images found: {len(df_images)}\")\n",
        "print(f\"   Number of classes: {len(class_names)}\")\n",
        "print(f\"   Classes: {sorted(class_names)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Count images per class\n",
        "class_counts = df_images['class'].value_counts().sort_index()\n",
        "print(\"\\n📈 Images per class:\")\n",
        "print(class_counts.to_string())\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify we have at least 5 classes with sufficient images\n",
        "if len(class_names) < 5:\n",
        "    print(f\"⚠️  Warning: Found only {len(class_names)} classes. Need at least 5 classes.\")\n",
        "    print(\"Please use a different dataset with at least 5 animal classes.\")\n",
        "else:\n",
        "    print(f\"✅ Dataset has {len(class_names)} classes - requirement met!\")\n",
        "\n",
        "# Select top 5 classes with most images\n",
        "top_5_classes = class_counts.head(5).index.tolist()\n",
        "print(f\"\\n🎯 Selected 5 classes for training: {top_5_classes}\")\n",
        "\n",
        "# Filter dataset to only include top 5 classes\n",
        "df_filtered = df_images[df_images['class'].isin(top_5_classes)].copy()\n",
        "\n",
        "# Verify each class has at least 200 images\n",
        "min_images_per_class = df_filtered['class'].value_counts().min()\n",
        "print(f\"\\n✅ Minimum images per class: {min_images_per_class}\")\n",
        "\n",
        "if min_images_per_class < 200:\n",
        "    print(f\"⚠️  Warning: Some classes have fewer than 200 images.\")\n",
        "    print(\"Proceeding with available images, but results may vary.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC5oyoLv8_V9"
      },
      "outputs": [],
      "source": [
        "# Visualize Class Distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Bar chart of class distribution\n",
        "class_counts_filtered = df_filtered['class'].value_counts()\n",
        "axes[0].bar(class_counts_filtered.index, class_counts_filtered.values, color='skyblue', edgecolor='navy')\n",
        "axes[0].set_xlabel('Animal Class', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('Number of Images', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Class Distribution (Top 5 Classes)', fontsize=14, fontweight='bold')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (idx, val) in enumerate(class_counts_filtered.items()):\n",
        "    axes[0].text(i, val + 5, str(val), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Pie chart\n",
        "axes[1].pie(class_counts_filtered.values, labels=class_counts_filtered.index,\n",
        "            autopct='%1.1f%%', startangle=90, colors=sns.color_palette(\"husl\", len(class_counts_filtered)))\n",
        "axes[1].set_title('Class Distribution Percentage', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"📊 Total images in filtered dataset: {len(df_filtered)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DEu72Tt8_V-"
      },
      "outputs": [],
      "source": [
        "# Implement 80/10/10 Data Split with Stratification\n",
        "print(\"🔄 Implementing 80/10/10 data split with stratification...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create class-to-index mapping\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(sorted(top_5_classes))}\n",
        "idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
        "\n",
        "print(f\"🏷️  Class mapping:\")\n",
        "for cls, idx in class_to_idx.items():\n",
        "    print(f\"   {idx}: {cls}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Add numeric class labels\n",
        "df_filtered['class_idx'] = df_filtered['class'].map(class_to_idx)\n",
        "\n",
        "# First split: 80% train, 20% temp (which will be split into val and test)\n",
        "train_df, temp_df = train_test_split(\n",
        "    df_filtered,\n",
        "    test_size=0.2,\n",
        "    stratify=df_filtered['class'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Second split: split temp into 50% val, 50% test (10% and 10% of original)\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df['class'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"📊 Data Split Summary:\")\n",
        "print(f\"   Training set: {len(train_df)} images ({len(train_df)/len(df_filtered)*100:.1f}%)\")\n",
        "print(f\"   Validation set: {len(val_df)} images ({len(val_df)/len(df_filtered)*100:.1f}%)\")\n",
        "print(f\"   Test set: {len(test_df)} images ({len(test_df)/len(df_filtered)*100:.1f}%)\")\n",
        "print(f\"   Total: {len(df_filtered)} images\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify stratification\n",
        "print(\"\\n📈 Images per class in each split:\")\n",
        "split_summary = pd.DataFrame({\n",
        "    'Train': train_df['class'].value_counts().sort_index(),\n",
        "    'Val': val_df['class'].value_counts().sort_index(),\n",
        "    'Test': test_df['class'].value_counts().sort_index()\n",
        "})\n",
        "print(split_summary)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify percentages\n",
        "print(\"\\n📊 Split percentages per class:\")\n",
        "split_percentages = pd.DataFrame({\n",
        "    'Train %': (train_df['class'].value_counts() / df_filtered['class'].value_counts() * 100).sort_index(),\n",
        "    'Val %': (val_df['class'].value_counts() / df_filtered['class'].value_counts() * 100).sort_index(),\n",
        "    'Test %': (test_df['class'].value_counts() / df_filtered['class'].value_counts() * 100).sort_index()\n",
        "})\n",
        "print(split_percentages.round(1))\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"✅ Data split completed with balanced class distribution!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esNXYXRa8_WA"
      },
      "outputs": [],
      "source": [
        "# Create YOLO Directory Structure\n",
        "print(\"📁 Creating YOLO directory structure...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Define base directory\n",
        "base_dir = Path('dataset')\n",
        "\n",
        "# Create directory structure\n",
        "dirs_to_create = [\n",
        "    base_dir / 'images' / 'train',\n",
        "    base_dir / 'images' / 'val',\n",
        "    base_dir / 'images' / 'test',\n",
        "    base_dir / 'labels' / 'train',\n",
        "    base_dir / 'labels' / 'val',\n",
        "    base_dir / 'labels' / 'test'\n",
        "]\n",
        "\n",
        "for dir_path in dirs_to_create:\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"   ✓ Created: {dir_path}\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"✅ Directory structure created successfully!\")\n",
        "\n",
        "# Display directory tree\n",
        "print(\"\\n🌳 Directory Structure:\")\n",
        "print(\"dataset/\")\n",
        "print(\"├── images/\")\n",
        "print(\"│   ├── train/\")\n",
        "print(\"│   ├── val/\")\n",
        "print(\"│   └── test/\")\n",
        "print(\"└── labels/\")\n",
        "print(\"    ├── train/\")\n",
        "print(\"    ├── val/\")\n",
        "print(\"    └── test/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ8xuB7e8_WB"
      },
      "outputs": [],
      "source": [
        "# Copy Images and Create YOLO Format Annotations\n",
        "print(\"📋 Copying images and creating YOLO format annotations...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "def create_yolo_annotation(img_path, class_idx, output_path):\n",
        "    \"\"\"\n",
        "    Create YOLO format annotation for an image.\n",
        "    For this dataset, we'll create a bounding box for the entire image\n",
        "    since we don't have pre-existing bounding box annotations.\n",
        "\n",
        "    YOLO format: class x_center y_center width height (all normalized 0-1)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read image to get dimensions\n",
        "        img = Image.open(img_path)\n",
        "        img_width, img_height = img.size\n",
        "\n",
        "        # Create bounding box covering the entire image\n",
        "        # Normalized coordinates: center at 0.5, 0.5, full width and height\n",
        "        x_center = 0.5\n",
        "        y_center = 0.5\n",
        "        width = 1.0\n",
        "        height = 1.0\n",
        "\n",
        "        # Write YOLO format annotation\n",
        "        with open(output_path, 'w') as f:\n",
        "            f.write(f\"{class_idx} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing {img_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "def process_split(df, split_name):\n",
        "    \"\"\"Process images and create annotations for a specific split.\"\"\"\n",
        "    print(f\"\\n🔄 Processing {split_name} split...\")\n",
        "\n",
        "    img_dir = base_dir / 'images' / split_name\n",
        "    label_dir = base_dir / 'labels' / split_name\n",
        "\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {split_name}\"):\n",
        "        try:\n",
        "            # Copy image\n",
        "            src_img = row['path']\n",
        "            filename = Path(row['filename']).stem\n",
        "            dst_img = img_dir / f\"{filename}.jpg\"\n",
        "\n",
        "            # Copy and convert image to RGB if needed\n",
        "            img = Image.open(src_img).convert('RGB')\n",
        "            img.save(dst_img, 'JPEG')\n",
        "\n",
        "            # Create YOLO annotation\n",
        "            label_file = label_dir / f\"{filename}.txt\"\n",
        "            if create_yolo_annotation(src_img, row['class_idx'], label_file):\n",
        "                success_count += 1\n",
        "            else:\n",
        "                error_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing {row['filename']}: {e}\")\n",
        "            error_count += 1\n",
        "\n",
        "    print(f\"   ✅ Successfully processed: {success_count} images\")\n",
        "    if error_count > 0:\n",
        "        print(f\"   ⚠️  Errors: {error_count} images\")\n",
        "\n",
        "    return success_count, error_count\n",
        "\n",
        "# Process each split\n",
        "train_success, train_errors = process_split(train_df, 'train')\n",
        "val_success, val_errors = process_split(val_df, 'val')\n",
        "test_success, test_errors = process_split(test_df, 'test')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"📊 Processing Summary:\")\n",
        "print(f\"   Training: {train_success} successful, {train_errors} errors\")\n",
        "print(f\"   Validation: {val_success} successful, {val_errors} errors\")\n",
        "print(f\"   Test: {test_success} successful, {test_errors} errors\")\n",
        "print(f\"   Total: {train_success + val_success + test_success} images processed\")\n",
        "print(\"=\" * 60)\n",
        "print(\"✅ Images copied and annotations created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oBuzvUx8_WC"
      },
      "outputs": [],
      "source": [
        "# Generate data.yaml Configuration File\n",
        "print(\"📝 Generating data.yaml configuration file...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get absolute paths\n",
        "abs_base_dir = Path(os.getcwd()) / base_dir\n",
        "\n",
        "# Create data.yaml configuration\n",
        "data_yaml = {\n",
        "    'path': str(abs_base_dir),\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'test': 'images/test',\n",
        "    'nc': len(top_5_classes),\n",
        "    'names': sorted(top_5_classes)\n",
        "}\n",
        "\n",
        "# Save data.yaml\n",
        "yaml_path = base_dir / 'data.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(data_yaml, f, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "print(\"✅ data.yaml created successfully!\")\n",
        "print(\"\\n📄 Configuration contents:\")\n",
        "print(\"=\" * 60)\n",
        "with open(yaml_path, 'r') as f:\n",
        "    print(f.read())\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gfAmDqL8_WC"
      },
      "outputs": [],
      "source": [
        "# Verify Dataset and Print Final Summary\n",
        "print(\"✅ PHASE 1 COMPLETE: Environment Setup & Dataset Preparation\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Count files in each directory\n",
        "def count_files(directory):\n",
        "    return len(list(directory.glob('*')))\n",
        "\n",
        "train_images = count_files(base_dir / 'images' / 'train')\n",
        "train_labels = count_files(base_dir / 'labels' / 'train')\n",
        "val_images = count_files(base_dir / 'images' / 'val')\n",
        "val_labels = count_files(base_dir / 'labels' / 'val')\n",
        "test_images = count_files(base_dir / 'images' / 'test')\n",
        "test_labels = count_files(base_dir / 'labels' / 'test')\n",
        "\n",
        "print(\"\\n📊 FINAL DATASET SUMMARY:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Dataset Location: {abs_base_dir}\")\n",
        "print(f\"Configuration File: {yaml_path}\")\n",
        "print(f\"\\nTotal Classes: {len(top_5_classes)}\")\n",
        "print(f\"Class Names: {sorted(top_5_classes)}\")\n",
        "print(f\"\\nData Split (80/10/10):\")\n",
        "print(f\"   Training:   {train_images} images, {train_labels} labels\")\n",
        "print(f\"   Validation: {val_images} images, {val_labels} labels\")\n",
        "print(f\"   Test:       {test_images} images, {test_labels} labels\")\n",
        "print(f\"   Total:      {train_images + val_images + test_images} images\")\n",
        "\n",
        "print(\"\\n📈 Images per Class per Split:\")\n",
        "print(split_summary)\n",
        "\n",
        "print(\"\\n✅ Validation Checks:\")\n",
        "print(f\"   ✓ Number of classes: {len(top_5_classes)} (requirement: 5)\")\n",
        "print(f\"   ✓ Images match labels in train: {train_images == train_labels}\")\n",
        "print(f\"   ✓ Images match labels in val: {val_images == val_labels}\")\n",
        "print(f\"   ✓ Images match labels in test: {test_images == test_labels}\")\n",
        "print(f\"   ✓ YOLO format annotations: Created\")\n",
        "print(f\"   ✓ data.yaml configuration: Created\")\n",
        "print(f\"   ✓ Stratified split maintained: Yes\")\n",
        "\n",
        "print(\"\\n🎯 Next Steps:\")\n",
        "print(\"   → Proceed to Phase 2: Model Configuration & Training\")\n",
        "print(\"   → Use the data.yaml file for training\")\n",
        "print(\"   → Dataset is ready for YOLO training!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAQBlRhl8_WD"
      },
      "outputs": [],
      "source": [
        "# Display Sample Images with Annotations\n",
        "print(\"🖼️  Displaying sample images from each class...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "fig.suptitle('Sample Images from Each Class (Training Set)', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, class_name in enumerate(sorted(top_5_classes)):\n",
        "    # Get a random image from this class\n",
        "    class_images = list((base_dir / 'images' / 'train').glob('*.jpg'))\n",
        "\n",
        "    if class_images:\n",
        "        # Read corresponding label to verify class\n",
        "        sample_img = random.choice(class_images)\n",
        "        img = cv2.imread(str(sample_img))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].set_title(f'{class_name}', fontsize=12, fontweight='bold')\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Sample visualization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYNGwT4m8_WD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfO85QlT8_WD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Animal Detection",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}